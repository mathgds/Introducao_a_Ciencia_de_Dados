{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathgds/introducao_a_ciencia_de_dados/blob/main/04_bias_variance_tradeoff_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entendendo o Compromisso entre Viés e Variância"
      ],
      "metadata": {
        "id": "_t7lBzQbcyBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Introdução\n",
        "Neste notebook, exploraremos os conceitos de viés e variância, que são cruciais para entender o desempenho dos modelos de aprendizado de máquina. Demonstrararemos esses conceitos usando dados sintéticos, modelos de regressão linear simples e validação cruzada."
      ],
      "metadata": {
        "id": "TQppiCV1c71u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Importando bibliotecas"
      ],
      "metadata": {
        "id": "OO7UKgRNdF6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures from\n",
        "\n",
        "# sklearn.preprocessing: Importa a partir do módulo preprocessing da biblioteca sklearn (scikit-learn).\n",
        "#                        O módulo preprocessing contém várias funções e classes para a transformação e pré-processamento de dados.\n",
        "#                        PolynomialFeatures é uma classe que gera características polinomiais a partir de características de entrada.\n",
        "#                        Essa transformação é útil para ajustar modelos de regressão polinomial.\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from mlxtend.evaluate import bias_variance_decomp\n",
        "# from mlxtend.evaluate: Importa a partir do módulo evaluate da biblioteca mlxtend. O mlxtend (Machine Learning Extensions)\n",
        "#                        é uma biblioteca que fornece uma variedade de ferramentas e extensões para aprendizado de máquina que não estão disponíveis diretamente no scikit-learn.\n",
        "\n",
        "# bias_variance_decomp: bias_variance_decomp é uma função que calcula a decomposição do viés e da variância de um modelo, ajudando a analisar o compromisso entre viés e variância."
      ],
      "metadata": {
        "id": "XZNpjR5bc-te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Criando dados sintéticos"
      ],
      "metadata": {
        "id": "QPBGMbffdUH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para gerar dados sintéticos\n",
        "def generate_synthetic_data(n_samples=100, noise=1.0, random_seed=42):\n",
        "# Parâmetros:\n",
        "# n_samples (100): Número de amostras a serem geradas.\n",
        "# noise (1.0): Nível de ruído a ser adicionado aos dados.\n",
        "# random_seed (42): Semente para garantir reprodutibilidade dos dados gerados.\n",
        "\n",
        "    np.random.seed(random_seed)\n",
        "     # Define a semente aleatória para garantir que os resultados sejam reprodutíveis.\n",
        "\n",
        "    X = np.linspace(0, 100, n_samples).reshape(-1, 1) # Criação das Amostras de Entrada\n",
        "    # np.linspace(0, 100, n_samples):\n",
        "    # Gera n_samples valores igualmente espaçados entre 0 e 100.\n",
        "    # reshape(-1, 1):\n",
        "    # Converte o array de uma dimensão em um array bidimensional com uma única coluna. Isso é necessário para que X tenha a forma correta para treinamento de modelos.\n",
        "\n",
        "    true_function = -0.0001 * X**3 + 0.01 * X**2 + 0.1 * X + 1\n",
        "    # Define a função verdadeira que gera os valores de y sem ruído. Aqui, a função é um polinômio cúbico (terceiro grau) com coeficientes específicos.\n",
        "\n",
        "    y = true_function + np.random.normal(scale=noise, size=X.shape)\n",
        "    # np.random.normal(scale=noise, size=X.shape):\n",
        "    # Adiciona ruído gaussiano aos valores da função verdadeira. O ruído é gerado com uma distribuição normal com desvio padrão especificado pelo parâmetro noise.\n",
        "    # y: Os valores finais da saída, que são a soma da função verdadeira e do ruído.\n",
        "\n",
        "    return X, y, true_function\n",
        "    # Retorna três valores:\n",
        "    # X: A matriz de características de entrada.\n",
        "    # y: A matriz de saídas com ruído.\n",
        "    # true_function: A função verdadeira usada para gerar y, sem ruído.\n",
        "\n",
        "# Gerando dados sintéticos\n",
        "X, y, true_function = generate_synthetic_data(n_samples=100, noise=2.0)"
      ],
      "metadata": {
        "id": "JUGb7mHqdYfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo em dados de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# O código utiliza a função train_test_split do scikit-learn para dividir os dados em conjuntos de treinamento e teste.\n",
        "# A divisão é feita de forma que 80% dos dados são usados para treinar o modelo e 20% são reservados para testar o modelo."
      ],
      "metadata": {
        "id": "sbGBTOhOddBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Modelo simples de regressão linear"
      ],
      "metadata": {
        "id": "ri_ha2VfdfjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando o modelo\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_train_pred = lin_reg.predict(X_train)\n",
        "y_test_pred = lin_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "rBAb5v7AdkWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotando os resultados\n",
        "plt.scatter(X_train, y_train, color='blue', label='Training data')\n",
        "plt.scatter(X_test, y_test, color='green', label='Testing data')\n",
        "plt.plot(X_train, y_train_pred, color='red', label='Linear regression')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target')\n",
        "plt.title('Linear Regression Model')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sGXxKx6qdn93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando os erros de treinamento e de teste\n",
        "train_error = mean_squared_error(y_train, y_train_pred)\n",
        "# train_error: Resultado do cálculo do MSE para os dados de treinamento.\n",
        "#              Representa a média dos quadrados dos erros entre os valores reais e os valores previstos para o conjunto de treinamento.\n",
        "\n",
        "test_error = mean_squared_error(y_test, y_test_pred)\n",
        "# test_error: Resultado do cálculo do MSE para os dados de teste.\n",
        "\n",
        "print(f'Training Error: {train_error}')\n",
        "print(f'Testing Error: {test_error}')"
      ],
      "metadata": {
        "id": "lddigFYNdqIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quando você observa que o Erro Quadrático Médio (MSE) para os dados de treinamento é maior do que o MSE para os dados de teste, isso é atípico, mas pode ocorrer por várias razões. Aqui está uma explicação das possíveis causas:\n",
        "\n",
        "1. Complexidade do Modelo e Ajuste\n",
        "\n",
        "- Sobreajuste: Normalmente, o sobreajuste ocorre quando o modelo se sai bem com os dados de treinamento, mas mal com os dados de teste. Nesses casos, o MSE de treinamento seria tipicamente menor do que o MSE de teste. Se o MSE de treinamento é maior, isso sugere que o modelo pode não estar sobreajustado, mas pode estar subajustado ou haver outro problema.\n",
        "\n",
        "2. Questões com os Dados\n",
        "\n",
        "- Qualidade dos Dados de Treinamento: A qualidade e a distribuição dos dados de treinamento podem diferir dos dados de teste. Se os dados de treinamento são ruidosos ou contêm anomalias, isso pode levar a um MSE de treinamento mais alto em comparação com o MSE de teste.\n",
        "\n",
        "- Simplicidade dos Dados de Teste: Os dados de teste podem ser mais simples ou ter menos variabilidade do que os dados de treinamento. Isso pode levar a um MSE mais baixo nos dados de teste, já que o modelo encontra mais fácil prever os dados de teste com precisão.\n",
        "\n",
        "3. Problemas de Treinamento do Modelo\n",
        "\n",
        "- Treinamento Insuficiente: Se o modelo não foi treinado adequadamente ou não convergiu corretamente, ele pode ter um desempenho pior nos dados de treinamento. Isso pode levar a um MSE de treinamento mais alto do que o MSE de teste. Por exemplo, se o processo de treinamento foi interrompido ou não foi permitido rodar por um número suficiente de épocas, o modelo pode não ter aprendido os padrões nos dados de treinamento bem.\n",
        "\n",
        "4. Variações Aleatórias\n",
        "- Semente Aleatória e Divisão dos Dados:\n",
        "Variações aleatórias na forma como os dados foram divididos ou amostrados podem levar a resultados incomuns. Diferentes execuções do mesmo experimento podem mostrar variabilidade devido a divisões aleatórias ou geração de dados.\n",
        "\n",
        "5. Regularização e Restrições\n",
        "\n",
        "\n",
        "- Regularização:\n",
        "Se um termo de regularização é aplicado e é forte, ele pode penalizar o modelo severamente por ajustar os dados de treinamento muito de perto. Isso pode levar a um MSE de treinamento mais alto em comparação com o MSE de teste."
      ],
      "metadata": {
        "id": "Q6E7LgjaF9Vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Modelo de Regressão Polinomial"
      ],
      "metadata": {
        "id": "HfvM3QzPdtrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar e plotar modelos polinomiais de diferentes graus\n",
        "degrees = [1, 2, 3, 15]\n",
        "colors = ['orange', 'red', 'black', 'cyan']\n",
        "predictions = []\n",
        "\n",
        "for degree, color in zip(degrees, colors):    # for percorre simultaneamente duas listas:\n",
        "                                              # degrees e colors, usando a função zip. Cada iteração fornece um valor de degree (grau do polinômio) e um valor de color\n",
        "                                              # (cor para a visualização).\n",
        "\n",
        "    poly_features = PolynomialFeatures(degree=degree, include_bias=False) # Esta classe do scikit-learn transforma as características de\n",
        "                                                                          # entrada em um polinômio de um determinado grau.\n",
        "\n",
        "    X_poly = poly_features.fit_transform(X)\n",
        "    # Ajusta o transformador aos dados de entrada X e transforma X para incluir características polinomiais de acordo com o grau especificado.\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_poly, y)\n",
        "    y_poly_pred = model.predict(X_poly)\n",
        "    predictions.append(y_poly_pred)\n",
        "    plt.plot(X, y_poly_pred, label=f'Degree {degree}', color=color)\n",
        "\n",
        "# Plotando os dados sintéticos e a função real\n",
        "plt.scatter(X, y, facecolors='none', edgecolors='black', label='Data')\n",
        "plt.plot(X, true_function, label='True Function', color='blue')\n",
        "plt.xlabel('Feature (X)')\n",
        "plt.ylabel('Target (Y)')\n",
        "plt.title('Data and Polynomial Fits')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FhBC9VROG4SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Compromisso entre Viés e Variância"
      ],
      "metadata": {
        "id": "rfaVy7XOd2sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O compromisso entre viés e variância é um conceito fundamental em aprendizado de máquina. Ele descreve o compromisso entre duas fontes de erro que afetam o desempenho de um modelo:\n",
        "\n",
        "- **Viés**: Erro devido a suposições excessivamente simplistas no algoritmo de aprendizado. Um viés alto pode fazer com que o modelo perca as relações relevantes entre as características e as saídas-alvo (subajuste).\n",
        "\n",
        "- **Variância**: Erro devido a uma complexidade excessiva no algoritmo de aprendizado. Uma variância alta pode fazer com que o modelo ajuste o ruído aleatório nos dados de treinamento (sobreajuste).\n",
        "\n",
        "Para visualizar o compromisso entre viés e variância, podemos plotar os erros de treinamento e teste para modelos com diferentes complexidades."
      ],
      "metadata": {
        "id": "InhiiNRUd_0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculando e plotando o MSE de treinamento e teste\n",
        "# Inicialização das Listas\n",
        "train_errors = []\n",
        "test_errors = []\n",
        "flexibility = []\n",
        "\n",
        "for degree in range(1, 21): # O loop for percorre os graus de polinômio de 1 a 20. Cada iteração testa um grau diferente de polinômio.\n",
        "    poly_features = PolynomialFeatures(degree=degree, include_bias=False) # Cria uma transformação polinomial para o grau atual.\n",
        "    X_train_poly = poly_features.fit_transform(X_train) # Aplica a transformação polinomial aos dados de treinamento.\n",
        "    X_test_poly = poly_features.fit_transform(X_test) # Aplica a transformação polinomial aos dados de teste.\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train_poly, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train_poly)\n",
        "    y_test_pred = model.predict(X_test_poly)\n",
        "\n",
        "    train_errors.append(mean_squared_error(y_train, y_train_pred))\n",
        "    test_errors.append(mean_squared_error(y_test, y_test_pred))\n",
        "    flexibility.append(degree)\n",
        "\n",
        "plt.plot(flexibility, train_errors, label='Training MSE', color='gray', marker='o')\n",
        "plt.plot(flexibility, test_errors, label='Test MSE', color='red', marker='o')\n",
        "plt.xlabel('Flexibility (Polynomial Degree)')\n",
        "plt.ylabel('Error')\n",
        "plt.title('Bias-Variance Tradeoff')\n",
        "plt.xticks(flexibility)  # Mostrar valores inteiros dos graus no eixo x\n",
        "plt.legend()\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DK99WHgxFXHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Conclusão"
      ],
      "metadata": {
        "id": "gdMFSEy0eE7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste notebook, exploramos os conceitos de viés e variância e demonstramos como eles afetam o desempenho dos modelos de aprendizado de máquina. Treinamos modelos de regressão linear e polinomial com dados sintéticos e visualizamos o compromisso entre viés e variância.\n",
        "\n",
        "Compreender e gerenciar o compromisso entre viés e variância é crucial para construir modelos que generalizem bem para novos dados não vistos. Ao equilibrar viés e variância, podemos alcançar um melhor desempenho e previsões mais confiáveis."
      ],
      "metadata": {
        "id": "YOaQ_76pelgR"
      }
    }
  ]
}